import cv2
import numpy as np
from typing import Dict, Tuple


class EyeTracker:
    def __init__(self):
        # YÃ¼z tespiti iÃ§in OpenCV'nin hazÄ±r modelini kullanÄ±yoruz
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        self.metrics = {
            'total_frames': 0,
            'face_detected_frames': 0,
            'eye_contact_frames': 0
        }

    def analyze_video(self, video_path):
        """Video dosyasÄ±nÄ± kare kare analiz eder."""
        cap = cv2.VideoCapture(video_path)

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break

            self.analyze_frame(frame)

        cap.release()
        return self.get_summary()

    def analyze_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:
        self.metrics['total_frames'] += 1

        # Siyah beyaz yap (Daha hÄ±zlÄ± tespit iÃ§in)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # YÃ¼zleri ara
        # scaleFactor=1.1, minNeighbors=5 standart iyi deÄŸerlerdir
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))

        frame_metrics = {'eye_contact': False, 'face_detected': False}

        if len(faces) > 0:
            self.metrics['face_detected_frames'] += 1
            frame_metrics['face_detected'] = True

            # En bÃ¼yÃ¼k yÃ¼zÃ¼ al (Kameraya en yakÄ±n kiÅŸi)
            faces = sorted(faces, key=lambda x: x[2] * x[3], reverse=True)
            (x, y, w, h) = faces[0]

            # YÃ¼zÃ¼n merkezini bul
            face_center_x = x + (w // 2)
            frame_center_x = frame.shape[1] // 2

            # YÃ¼z, ekranÄ±n merkezine yakÄ±n mÄ±? (Tolerans %30)
            threshold = frame.shape[1] * 0.30

            if abs(frame_center_x - face_center_x) < threshold:
                frame_metrics['eye_contact'] = True
                self.metrics['eye_contact_frames'] += 1

            # GÃ¶rselleÅŸtirme (Kare iÃ§ine al)
            color = (0, 255, 0) if frame_metrics['eye_contact'] else (0, 0, 255)
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            cv2.putText(frame, "ODAK", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        return frame, frame_metrics

    def get_summary(self) -> Dict:
        # EÄŸer hiÃ§ yÃ¼z bulunamadÄ±ysa 0 dÃ¶ndÃ¼r
        if self.metrics['face_detected_frames'] == 0:
            score = 0
            recs = ["âš ï¸ Videoda yÃ¼zÃ¼nÃ¼z tespit edilemedi. IÅŸÄ±klandÄ±rmayÄ± kontrol edin veya kameraya daha yakÄ±n durun."]
        else:
            # Sadece yÃ¼zÃ¼n gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ anlarÄ± baz alarak puanla
            score = (self.metrics['eye_contact_frames'] / self.metrics['face_detected_frames']) * 100

            recs = []
            if score < 50:
                recs.append("ğŸ”´ Ä°zleyiciyle gÃ¶z temasÄ±nÄ±z zayÄ±f. Kameraya daha sÄ±k bakÄ±n.")
            elif score < 80:
                recs.append("ğŸŸ¡ GÃ¶z temasÄ±nÄ±z iyi ama artÄ±rÄ±labilir.")
            else:
                recs.append("ğŸŸ¢ Harika gÃ¶z temasÄ±! Ä°zleyiciyle baÄŸ kuruyorsunuz.")

        return {
            'overall_eye_contact_score': round(score, 1),
            'recommendations': recs
        }